# MNIST – (сокращение от «Modified National Institute of Standards and Technology»)
# – база данных образцов рукописного написания цифр
import keras
import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras
from keras.layers import Dense, Flatten
from keras.datasets import mnist

# загуржаю данные этой библиотеки
# Здесь 60 000 изображений в обучающей выборке и 10 000 – в тестовой. Мы будем использовать определения:
# x_train – изображения цифр обучающей выборки;
# y_train – вектор соответствующих значений цифр (например, если на i-м изображении нарисована 5, то  y_train[i] = 5);
# x_test – изображения цифр тестовой выборки;
# y_test – вектор соответствующих значений цифр для тестовой выборки.
# Каждое изображение имеет размер 28х28 пикселей и представлено в градациях серого
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Теперь нужно ответить на второй вопрос о структуре сети. Строгого ответа на него нет,
# т.к. структура выбирается самим разработчиком исходя из его представлений о решении этой задачи.
# Общий ориентир здесь такой: для распознавания графических образов хорошо себя показали сверточные НС.
# Но мы о них пока еще ничего не знаем, поэтому воспользуемся обычной полносвязной НС с
#
# 28 x 28 = 784 входами;
# 128 нейронами скрытого слоя;
# 10 нейронами выходного слоя.
# В качестве функций активации скрытого слоя выберем популярную на сегодняшний день ReLu, а у выходных нейронов –
# softmax, т.к. мы хотим интерпретировать выходные значения в терминах вероятности принадлежности к тому или иному
# классу цифр.
# Первый слой должен преобразовывать изображение 28x28 пикселей в вектор из 784 элементов.
# Для такой операции в Keras можно создать слой специального вида – Flatten
# Следующий слой создадим с помощью уже известного нам класса Dense, который свяжет все 784 входа со всеми 128
# нейронами. И такой же последний слой из 10 нейронов, который будет связан со всеми 128 нейронами предыдущего слоя.
model = keras.Sequential([
    Flatten(input_shape=(28, 28, 1)),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])

# вывод структуры в консоль
#print(model.summary())

# Необходимо входные значения вектора x стандартизировать так, чтобы они находились в диапазоне от 0 до 1
# Здесь каждое значение тензоров x_train и x_test будет делиться на максимальное число 255, которое они могут принимать.
# На выходе получим вещественные величины от 0 до 1.
x_train = x_train / 255
x_test = x_test / 255

# Еще нам нужно подготовить правильный формат выходных значений
# нам нужен вектор с 1 на месте соответствующего числа, т.к. наша НС имеет 10 выходов, и каждый выход будет
# соответствовать определенной цифре: от 0 до 9.
# В Keras уже имеется функция, которая все это делает.
y_train_cat = keras.utils.to_categorical(y_train, 10)
y_test_cat = keras.utils.to_categorical(y_test, 10)

# Теперь выберем функцию потерь (loss function) и способ оптимизации градиентного алгоритма.
# Лучше всего начинать с категориальной кросс-энтропии:
#
# categorical_crossentropy
#
# и активационной функции выходных нейронов softmax. Функцию активации мы уже такую прописали,
# осталось указать этот критерий качества:
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# запуск модели обучения
model.fit(x_train, y_train_cat, batch_size=32, epochs=10, validation_split=0.2)
# batch_size = 32 – это размер батча (32 картинки), после которых будет выполняться корректировка весов
# validation_split = 0,2 – разбиение обучающей выборки на собственно обучающую и проверочную. Значение 0,2 определяет,
# что для каждой эпохи 20% случайных картинок из обучающей
# выборки будут помещаться в выборку валидации. 20% - это довольно частое значение для создания проверочной выборки
# (ее, как правило, выбирают из диапазона от 10% до 30%).

# Проверка работы сети на тестовом множестве:
model.evaluate(x_test, y_test_cat)
# Метод evaluate прогоняет все тестовое множество и вычисляет значение критерия качества и метрики.

# выполним распознавания какого-либо тестового изображения:
n = 1
x = np.expand_dims(x_test[n], axis=0)
res = model.predict(x)
print(res)

# И полагаем, что максимальное значение как раз и будет соответствовать нужному классу. В данном случае – это число
# 9.9881822e-01 третьего выхода, то есть, для цифры 2. Чтобы было проще воспринимать выходную информацию, будем выводить
# номер максимального числа из этого вектора. Для этого воспользуемся довольно удобной функцией argmax модуля numpy:
print(np.argmax(res))

# И, еще, отобразить на экране это тестовое изображение:
plt.imshow(x_test[n], cmap=plt.cm.binary)
plt.show()


